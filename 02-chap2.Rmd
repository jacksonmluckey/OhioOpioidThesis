# Data and Methods

```{r variableOrdering}
################################
# Disability Variable Ordering #
################################
base_disability_list <- c("disability_percent_under5", "disability_percent_5to17", "disability_percent_18to34", "disability_percent_35to64", "disability_percent_65to74", "disability_percent_75andup")

# adds a suffix to a string
# used for generating the male and female disability lists
add_suffix <- function(string, suffix) {
  string <- paste0(string, suffix)
  string
}

# create male, female, and unified disability variable ordering list
# and then turn them back into usable vectors
# instead of lists (to avoid the [[]] nonsense and ambiguity with tidyselect)
male_disability_ordering <- base_disability_list %>%
  map(add_suffix, "_male") %>%
  as.character()
female_disability_ordering <- base_disability_list %>%
  map(add_suffix, "_female") %>%
  as.character()
disability_ordering <- c(male_disability_ordering, female_disability_ordering)

###############################
# Education Variable Ordering #
###############################
education_ordering <- c("education_b_percent_highschool_or_less", "education_b_percent_college_or_more",
                        "education_s_percent_less_than_highschool", "education_s_percent_highschool",
                        "education_s_percent_ged", "education_s_percent_some_college", "education_s_percent_college",
                        "education_s_percent_graduate")

############################
# Master Variable Ordering #
############################
misc_variable_ordering <- c("OD_rate", "income_pc_individual", "percent_white", "percent_black", "population", "deaths")
master_variable_ordering <- c(misc_variable_ordering, education_ordering, disability_ordering)
```

## Data

Census data is stored by table, year, geography, and survey. Each survey has a different set of tables, and surveys can differ from year to year [@UnderstandingACSBasics2020]. Surveys are only available for specific geographic regions, with broader, less frequent surveys covering a greater variety of geographies. Geographies include states, counties, census tracts, and school districts [@GeographicAreasCovered2020].

The majority of my independent variables were sourced from the census American Community Survey. The American Community Survey, or ACS, "provides a detailed portrait of the social, economic, housing, and demographic characteristics of Americaâ€™s communities" [@UnderstandingACSBasics2020]. ACS data is available on a geographic hierarchy, going from census tracts to the United States as a whole. This thesis uses ACS data aggregated at the county level from the one-year survey [@GeographicAreasCovered2020]. Due to changes in the way that ACS data were collected in 2010, the dataset includes ACS data from the years 2012 to 2018. Tables are not necessarily consistent between years [@UnderstandingACSBasics2020].

The variables "DeathRateCDC" and "UrbanRural" come from CDC data. They are sourced from the "Drug Poisoning Mortality by County" dataset, which is published by the National Center for Health Statistics. The death rate is age-adjusted. The data was paired with the census and overdose data using the FIPS code, which is a GEOID [@calgaryNCHSDrugPoisoning].

### Sample Size

Unfortunately, not all counties in Ohio are included in the American Community Survey. Only counties with a population of 65,000 or greater are included in the one year American Community Survey [@GeographicAreasCovered2020]. In total, the sample includes 39 out of Ohio's 88 counties. Since the census data is censored based on county population, there is selection bias in the sample. This means that my results may be an inaccurate reflection of reality if there is correlation between a county's population and the county's fatal drug overdose rate. Given that the literature suggests that rural areas have suffered from greater increases in overdose rates, it is likely that there is correlation between county population and the overdose rate, meaning that there is likely selection bias in the dataset.

Counties excluded in the one year American Community Survey are available in other U.S. Census Bureau datasets. Counties with at least a population of 20,000 are included in the one year American Community Survey supplemental estimates, which provide a more limited version of the tables included in the broader one year American Community Survey. Furthermore, the ACS five year estimates include many counties excluded from the one-year estimates, and the decennial survey includes all areas [@UnderstandingACSBasics2020].

```{r mapCountiesIncludedInSample, fig.cap="Counties included in the data", eval=FALSE}
# eval=FALSE because it needs to be updated to work with my improved dataset
counties_included <- df %>%
  group_by(county, GEOID) %>%
  summarize(population = mean(population),
            year_count = n()) %>%
  ungroup() %>%
  mutate(included_at_least_once = !is.na(population)) %>%
  mutate(included_every_year = if_else(year_count == 7, TRUE, FALSE)) %>%
  mutate(included = case_when(included_at_least_once == FALSE ~ "No",
                              included_every_year == TRUE ~ "Yes",
                              included_at_least_once == TRUE & included_every_year == FALSE ~ "Some years")) %>%
  select(GEOID, included)

base_map %>%
  left_join(counties_included, by = c("GEOID" = "GEOID")) %>%
  mutate(included = if_else(is.na(included), "No", included)) %>%
  ggplot(aes(geometry = geometry, fill = included)) +
  geom_sf() +
  labs(fill = "Included in Sample?",
       title = "Counties Included in Sample",
       x = "",
       y = "") +
  theme_map +
  scale_fill_viridis_d()
```

### Variable Summary Statistics

For the education variables, "_s_" refers to small bins (e.g. 11th grade education, 12th grade education), whereas "_b_" refers to the aggregation of multiple small bins (e.g. high school or less, college or more). The big bins are calculated by aggregating the smaller bins, and exclude individuals with some amount of college education but less than a bachelors-level degree. The original data was provided as a raw count for each education level (i.e. number of people with an 11th grade education, number of people with a 12th grade education, and so on). To convert it into percentages, I divided each raw count by the total population of the county and assumed that all individuals would be included in one--and only one--column.

Race is included as the variable "percent_black". Racial demographic data is represented this way because census demographic data that distinguishes between cacausian and latinx is significantly more challenging to work with, as the categories provided do not neatly add up the total population of the county. Since heroin was considered an urban black drug from the late 1930s until recently, "percent_black" seemed an effective enough variable for assesing the role of race in drug overdose rates [@macyDopesickDealersDoctors2018; @quinonesDreamlandTrueTale2016; @whiteSlayingDragonHistory1998].

Disability is broken into age and sex bins. These bins are kept small because in order to aggregate them, I would need each county-year pair's population broken down into age and sex bins. The type of disability was ignored, as the literature suggested that painful, physical disabilities would have the greatest impact, and the census-provided disability bins only seperated out deafness and blindness.

The majority of variables are in percentage form. These variables, excluding "OD_rate", have the term "percentage" in their name. Percentages are calculated using the raw population for that year, and are stored in the format XX.X%, rather than .XXX%. Percentage, or per capita, form is used to isolate the role of county population on the fatal drug overdose rate.

```{r summaryStatsPrep, include=FALSE, eval=FALSE}
# eval=FALSE because it needs to be updated to work with my improved dataset
summary_stats <- df %>%
  select(-GEOID, -county, -year) %>%
  select(all_of(master_variable_ordering)) %>%
  summarize_all(list(min, max, mean, sd), na.rm = TRUE) %>%
  pivot_longer(everything()) %>% # turns into a 2 column df
  mutate(func = str_match(name, "_fn([1-4])")[,2]) %>% # func identifies which transformation was used
  mutate(func = case_when(func == 1 ~ "Min", # converts func into a meaninful label
                          func == 2 ~ "Max",
                          func == 3 ~ "Mean",
                          func == 4 ~ "SD")) %>%
  mutate(name = str_remove(name, "_fn[1-4]")) %>% # strips the suffix which was turned into func
  pivot_wider(names_from = func, values_from = "value") %>% # untidies but makes easy to use
  mutate(`Variable Name` = name, # make the variable name label better
         name = NULL) %>%
  select(`Variable Name`, everything()) %>% # gets the variable name in front
  mutate(`CoV` = SD / Mean) %>%
  recode_vars() %>%
  select(-rawVarName, -Label) %>%
  arrange(Category)

build_group_vars_category_tibble <- function(df) {
  df %>%
    mutate(row_num = 1:n()) %>%
    group_by(Category) %>%
    summarize(first_row = first(row_num)) %>%
    arrange(first_row)
}

summary_stats_index <- build_group_vars_category_tibble(summary_stats)

group_rows_by_tibble <- function(kable_table, tibble) {
  for (i in 1:nrow(tibble)) {
    # handles the out of bounds for i+1 issue
    if (i != nrow(tibble)) {
      kable_table <- kable_table %>%
        pack_rows(group_label = tibble[[i,1]], start_row = tibble[[i,2]], end_row = (tibble[[i+1,2]] - 1))
    } else {
      kable_table <- kable_table %>%
        pack_rows(group_label = tibble[[i,1]], start_row = tibble[[i,2]], end_row = nrow(tibble))
    }
  }
  kable_table
}
```

```{r summaryStatsAllVariables, results="asis", eval = FALSE}
# eval=FALSE because it needs to be updated to work with my improved dataset
summary_stats %>%
  select(-Category) %>%
  kable(caption = "Variable Summary Statistics",
        format.args = list(scientific = FALSE,
                           big.mark = ",",
                           digits = 3),
        format = "pandoc",
        booktabs = T) %>%
  group_rows_by_tibble(summary_stats_index) %>%
  kable_styling(latex_options="scale_down")
```

In general, it appears that the coefficient of variation of the disability variables decreases as the age bin increases. This makes intuitive sense, as disability rates presumably increase as age increases, so there would be less variability as age increases, especially in counties with a smaller population. The presence of observations with zero children under the age of five with disabilities confirms this intuition. Unsuprisingly, it appears that disability rates soar after the age of 65. This might be because of individuals gaining access to healthcare through Medicare coverage, and therefore getting a formal diagnosis. Interestingly, the male disability rate is consistently higher than the female disability rate until the age of 75.

The opioid overdose death rate varied significantly between observations. In fact, the counties with the highest rate had almost thirty times as many deaths per capita than the counties with the lowest rate. Furthermore, the sample excludes many counties in Ohio, meaning that the variability of the overdose death rate could be even higher. The mean overdose death rate is approximately 3.75 deaths per year per 10,000 people.

County populations in the sample range from just over 35,000 to almost 900,000. The inclusion of counties with under 65,000 population, as the census documentation claims that such counties are not included in the American Community Survey one year estimates [@GeographicAreasCovered2020]. Cuyahoga County, which contains the city of Cleveland, consistently has the highest population according to the American Community Survey estimates. Franklin County, which contains the city of Columbus, closely follows. Oddly, these estimates are very far off from the population table on data.census.gov, suggesting that the two American Community Survey tables calculate population in a different way. Given that both counties have several hundred thousand more people in the DP05 table, a possible explanation is that the table I used only includes adults in the estimate [@FranklinCountyVs2020].

There is significant variation in education levels between counties. While in some counties barely ten percent of the adult population has a college degree, in others more than half of the population does. On average, approximately 25% of a county's population has at least a bachelors degree, just under 50% has a high school degree or less, and the rest attended some amount of college without obtaining a bachelors. Interestingly, the education level with the least variation between counties is attending college without achieving a bachelors degree, which varies by less than 50%. The other levels vary by at least 100%, and in some cases by almost an order of magnitude.

Race varies dramatically between counties. Some counties are over 95% white, whereas others are barely over 60%. On average, counties included in the sample are approximately 86% white. If all counties were included in the sample, the mean would likely be higher, as more rural, and therefore smaller, counties in Ohio tend to be more racially homogenous.

```{r overdoseRateDistribution, fig.cap="Distribution of drug overdose rate", eval=FALSE}
# eval=FALSE because it needs to be updated to work with my improved dataset
df %>%
  filter(!is.na(OD_rate)) %>% # drop the NA rows that occur because of the missing 2018 deaths data
  ggplot(aes(x = OD_rate)) +
  geom_histogram(bins = 25) +
  theme_minimal() +
  ggtitle("Distribution of Overdose Rate") +
  labs(y = "", x = "Overdose Rate (Deaths per 10,000)") +
  theme(axis.text.y = element_blank(),
        plot.title = element_text(hjust = 0.5))
```

The distribution of the fatal drug overdose rate between counties suggests that censoring may be occuring from the bottom. This is because the right-side tail is significantly longer and fatter than the left-side tail [@hareThesisMeetings2019]. Furthermore, no observations reach zero, further suggesting data censoring [@hillPrinciplesEconometrics2011].

```{r raceDistribution, fig.cap="Distribution of percent black by county", eval=FALSE}
# eval=FALSE because it needs to be updated to work with my improved dataset
df %>%
  ggplot(aes(x = percent_black)) +
  geom_histogram(bins = 20) +
  theme_minimal() +
  ggtitle("Distribution of Percent Black") +
  labs(x = "Percent Black", y = "") +
  scale_x_continuous(labels = function(x) paste0(x, "%")) + # adds percentage signs; scales::percent assumes .XXX format, while I have XX.X
  theme(axis.text.y = element_blank(),
        plot.title = element_text(hjust = 0.5))
```

The distribution of percent black by county does not indicate any data issues. While observations do not occur in a perfect Gaussian bell curve, there is no reason to believe that the data is censored.

### Maps

```{r mapPercentBlack, fig.cap="Map of Ohio counties by percent black", eval=FALSE}
# eval=FALSE because it needs to be updated to work with my improved dataset
df %>%
  group_by(county, GEOID) %>%
  summarize(percent_black = mean(percent_black, na.rm = TRUE)) %>%
  full_join(base_map, by = c("GEOID" = "GEOID")) %>%
  ggplot(aes(fill = percent_black, geometry = geometry)) +
  geom_sf() +
  theme_map +
  scale_fill_viridis_c() +
  labs(subtitle = "Grey means excluded from sample",
       title = "Percent Black by County",
       fill = "% Black")
```

The yellow county is Cuyahoga County, which contains the city of Cleveland. Before the 1990s, Cleveland was considered to be the only region in Ohio to contain a significant heroin market [@quinonesDreamlandTrueTale2016]. Therefore, we would expect Cleveland to have started off with an above average drug overdose death rate. With the rise of the Xalisco boys and the introduction of OxyContin, heroin markets spread across the state [@macyDopesickDealersDoctors2018; @quinonesDreamlandTrueTale2016]. Hence, we would expect Cleveland, and therefore Cuyahoga County, to have a higher than average overdose rate prior to the mid 90s, and for other counties to have a larger increase in their overdose death rate.

## Methods

I used the R package Tidycensus to download census data. Tidycensus was created by Kyle Walker and is maintained by a community on GitHub. Tidycensus allows "R users to return Census and ACS data as tidyverse-ready data frames, and optionally returns a list-column with feature geometry for many geographies". The "list-column with feature geometry" allows the R user to easily draw maps using the downloaded census data and ggplot2. Dataframes can be downloaded in either a wide or tidy format, and brief descriptions of each variable are available. The package is an API wrapper for data.census.gov, and the API calls it creates can be accessed and manually ran using packages such as rvest. The package supports both American Community Survey and Decennial data. To pull down data with Tidycensus, you need to know the variable/table name, the year, the geographic level, and the survey.

 To identify the variables and tables available from a survey, I used the command `tidycensus::load_variables(year, survey)`, where year is a year in numerical format (e.g. 2018), and survey is a survey in character format (e.g. "acs1"). To search for variables within a specific table in the survey, filter the output of `load_variables()` with `filter(stringr::str_detect(name, pattern))`, where pattern is the table name followed by an underscore. This was abstracted away as Variable names can be merged with the tidy output of another Tidycensus call by using `rename(variable = name)` to change the column names of the output of `load_variables()` to match the column names of a Tidycensus dataframe, and then using `dplyr::left_join(tidycensus_dataframe, output_of_load_variables, by = c("name" = "name"))`.
 
The geographical level, survey, and year are all easier to determine. Geographical levels are things like state, county, school district, census tract, and congressional district. They are represented as characters. Not all geographical levels are supported by Tidycensus, and not all surveys are available for all geographies. Surveys include the different American Community Surveys, the Decennial census, and supplemental estimates. They can be found on the U.S. Census's website. Finally, year is simply a valid year for that survey provided as a number.

To pull down actual data from census.data.gov using Tidycensus, you use one of three functions depending on the survey that you are working with. To work with the decennial census, use `get_decennial()`. To work with American Community Survey data, use `get_acs()`. Finally, use `get_estimates()` to work with the Census Bureau's population estimates API. If you download the data in wide format, Tidycensus returns a table with the columns `GEOID` and `NAME`, which refer to the geographical region, and two columns, `Table_Variable + E` and `Table_Variable + M`, for each variable in the table. For example, if the table was "someTable", and it only included the variables "001" and "002", the returned dataframe would included the columns `someTable_001E, someTable_001M, someTable_002E, someTable_002M`. E refers to estimate, while M refers to margin of error. Finally, if you included the argument `geometry = TRUE` in the call, there will be a column `geometry` that includes the data required to draw a map of the geographical regions included in the call.

[@walkerTidycensus; @tidycensus2020]

In order to better use Tidycensus, I wrote custom functions to accomplish several repeated tasks. One function, `get_census_tables_multiple_years(table, years)`, allows the user to download multiple years of a particular census table at once. The functions accept a table code and year range, and downloads the table for each year, pivot it into a wide format, adds a year column, and binds the rows of the resulting dataframes into one master dataframe, which is returned. Another function, `clean_county_col(df)`, modifies the "county" column, removing the string "County, Ohio" from each entry in order to make it easier to join with other datasets.

Census tables were identified through several means. Using Tidycensus's "load_variables" function, I created a dataframe of all variables covered in the package and filtered it using keywords and R's grep wrapper. Keywords were selected by brainstorming off of the hypothesis that the literature put forward. For example, I used the keyword "disability" for the disability variables, "median income" and "average income" and "mean income" for income, and so on. Furthermore, Reed's data services librarian, Mahria Lebow, helped me identify relevant census tables by examining the census table shells and going through the documentation available at data.census.gov [@lebowCensusHelp]. I decided to start off with one year American Community Survey data because it had a relatively limited number of variables, making it easier to work with, and it provided more statistical power than relying on the decennial survey, which at best offered three rows per county (1990, 2000, 2010).

Plots, graphs, and maps that appear within this thesis were produced using ggplot2 unless otherwise noted. ggplot2 is a R package that is part of the Tidyverse universe of R packages. The package allows for a R user to quickly produce aesthetically appealing graphs and maps using any tidy dataset. Visualizations made in ggplot2 are designed using a standardized "grammar of graphics", which helps keep the visual appearance of a variety of different types of visualizations consistent [@wickhamGgplot2ElegantGraphics2016]. One major advantage of working with Tidyverse-compliant packages such as ggplot2 and Tidycensus is that they are designed to work together easily. This allows a R user to go directly from pulling down census data to making maps without having to reshape data or otherwise perform tedious data cleaning, wrangling, and preparation tasks [@walkerTidycensus2020; @wickhamGgplot2ElegantGraphics2016].

Initial regressions were performed using ordinary least squares multiple regression. These econometric models are similar to simple linear regression, but allow for multiple explanatory variables. Excluding the intercept, all parameters show the change in the dependent variable given a unit change in that particular explanatory variable *ceterus paribus*, meaning with all other explanatory variables held constant. For this econometric model to work, several assumptions must be fulfilled, such as having homoskedastic errors and no exact collinearity between explanatory variables [@hillPrinciplesEconometrics2011]. While most of the assumptions are fulfilled, it is possible that there is heteroskedacity in the errors, as the census reports higher a margin of error for smaller counties.

In addition to the simple linear regression models, a model with a censored dependent variable is also used. This model, referred to as a Tobit model, is used when there is censoring of the dependent variable [@hareThesisMeetings2019]. Censoring is when a sizable portion of the observations of the dependent variable takes a particular value, often zero [@hareThesisMeetings2019; @hillPrinciplesEconometrics2011]. For example, a national survey of deaths per household would be censored, as most households would record zero deaths for any particular year. When censoring occurs, least squares regression cannot draw an accurate line through the center of the scattered data, leading to biased and inconsistent parameter estimates. To rectify this, Tobit models calculate the likelihood probability by splitting the probabilities between censored and uncensored observations, and then multiplying these probabilties. This accounts for the data falling into two categories--censored and uncensored--and results in less biased and more consistent parameter estimates than ordinary least squares regression models [@hillPrinciplesEconometrics2011]. In all cases, the regression models were converted into tables using the package Stargazer, which summarizes regressions and prints visually appealing LaTeX tables [@marekhlavacStargazer2018].

COUNTY FIXED EFFECTS [@hanck10FixedEffects2019]